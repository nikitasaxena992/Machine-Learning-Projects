{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SENTIMENT ANALYSIS\n",
    "\n",
    "Sentiment analysis is widely applied to voive of the customer material such as reviews and survey responses,online and social media and healthcare materials for application that range from marketing to customer service to clinical medicine.  In this project we are analyzing the zomato review based on the food."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.express as px   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### reading csv\n",
    "df = pd.read_csv(\"E:/MyLearnings/Machine_learning/SentimentAnalysis/data/Reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We are doing visualization here by plottoing bar graph an the basis of score which is give in dataset..\n",
    "fig = px.histogram(df, x= \"Score\")\n",
    "fig.update_traces(marker_color = \"cyan\", marker_line_color = 'rgb(8,48,107)',marker_line_width = 1.5)\n",
    "fig.update_layout(title_text = \"Product Score\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud \n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "from nltk.classify import apply_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are craeting word cloud of the whole revi ew text\n",
    "# stop = set(stopwords.words('english'))\n",
    "stopwords.update([\"br\",\"href\"]) \n",
    "text = \" \".join(review for review in df.Text)\n",
    "wordcloud = WordCloud(stopwords = stopwords).generate(text)\n",
    "plt.imshow(wordcloud, interpolation = \"bilinear\")\n",
    "plt.axis(\"off\")             \n",
    "plt.savefig(\"word.png\")\n",
    "plt.show()                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ### Here we have made chnges if the score is greater than 3 then we have converted into 1 and for less than 3 we  have converted it into -1\n",
    "df = df[df[\"Score\"] !=3]\n",
    "df['sentiment'] = df['Score'].apply(lambda rating: +1 if rating > 3 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We have intialized 1 for positive sentiment and -1 for negative sentiments\n",
    "positive = df[df['sentiment'] == 1]\n",
    "negative = df[df['sentiment'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here we have counting the total number of stopwords\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating word cloud for positive text reviews\n",
    "stopwords.update([\"br\",\"href\",\"good\",\"great\"])\n",
    "pos = \" \".join(review for review in positive.Summary)\n",
    "wordcloud2 = WordCloud(stopwords = stopwords).generate(pos)\n",
    "plt.imshow(wordcloud2, interpolation = 'bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating positive and negative histogram graphs\n",
    "df['sentiment'] = df['sentiment'].replace({-1: 'negative'})\n",
    "df['sentiment'] = df['sentiment'].replace({1:'positive'})\n",
    "fig = px.histogram(df, x = \"sentiment\")\n",
    "fig.update_layout(title_text = \"Product Sentiment\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing punctuation from text\n",
    "def remove_punctuation(text):\n",
    "    final = \"\".join(u for u in text if u not in (\"?\",\".\",\";\",\":\",\"!\",'\"'))\n",
    "    return final\n",
    "df['Text'] = df['Text'].apply(remove_punctuation)\n",
    "df = df.dropna(subset=['Summary'])\n",
    "df['Summary'] = df['Summary'].apply(remove_punctuation)\n",
    "######## After removing punctuations we are having text\n",
    "df['Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initalizing the summary and sentiments in new dataframe thats is dfNew\n",
    "dfNew = df[['Summary','sentiment']]\n",
    "dfNew.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we will have machine learning model for that we have dived the random test and train data\n",
    "index = df.index\n",
    "df['random_number'] = np.random.randn(len(index))\n",
    "train = df[df['random_number'] <=0.8]\n",
    "test = df[df['random_number'] > 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### we have train the summary wiyh countvectorizer and same doing with test summary\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(token_pattern = r'\\b\\w+\\b')\n",
    "train_matrix = vectorizer.fit_transform(train['Summary'])\n",
    "test_matrix = vectorizer.transform(test['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implementing logistic regression                                  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_matrix\n",
    "X_test = test_matrix\n",
    "y_train = train['sentiment']\n",
    "\n",
    "y_test = test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculating the predictions \n",
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "new = np.asarray(y_test)\n",
    "confusion_matrix(predictions,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
